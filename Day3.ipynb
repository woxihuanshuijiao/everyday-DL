{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性代数：\n",
    "1. 向量的长度：所有元素的平方求和再开根号\n",
    "2. 矩阵乘法：将向量在空间上“扭曲”\n",
    "3. 特征向量：矩阵做变换时方向不会被改变的向量（不一定每个矩阵都有）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([3.0])\n",
    "y = torch.tensor([2.0])\n",
    "\n",
    "x**y #指数运算，x的y次方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4],\n",
       "        [ 5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14],\n",
       "        [15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(4,5)\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  5, 10, 15],\n",
      "        [ 1,  6, 11, 16],\n",
      "        [ 2,  7, 12, 17],\n",
      "        [ 3,  8, 13, 18],\n",
      "        [ 4,  9, 14, 19]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(A.T)  #转置矩阵\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20, dtype=torch.float32).reshape(5, 4)\n",
    "B = A.clone() #只有克隆才可以重新分配内存\n",
    "A, A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.,   1.,   4.,   9.],\n",
       "        [ 16.,  25.,  36.,  49.],\n",
       "        [ 64.,  81., 100., 121.],\n",
       "        [144., 169., 196., 225.],\n",
       "        [256., 289., 324., 361.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11],\n",
       "          [12, 13, 14, 15],\n",
       "          [16, 17, 18, 19]],\n",
       " \n",
       "         [[20, 21, 22, 23],\n",
       "          [24, 25, 26, 27],\n",
       "          [28, 29, 30, 31],\n",
       "          [32, 33, 34, 35],\n",
       "          [36, 37, 38, 39]]]),\n",
       " tensor(780),\n",
       " tensor([[20, 22, 24, 26],\n",
       "         [28, 30, 32, 34],\n",
       "         [36, 38, 40, 42],\n",
       "         [44, 46, 48, 50],\n",
       "         [52, 54, 56, 58]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(20*2).reshape(2, 5, 4) # 2个 4*5大小的矩阵\n",
    "a, a.sum(), a.sum(axis=0) #sum(axis=n) 意思是在第n维上面求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([180, 190, 200, 210])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(axis=[0,1]) # 两个维度求和 结果应该和第3个维度相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0455, 0.0833, 0.1154],\n",
       "          [0.1429, 0.1667, 0.1875, 0.2059],\n",
       "          [0.2222, 0.2368, 0.2500, 0.2619],\n",
       "          [0.2727, 0.2826, 0.2917, 0.3000],\n",
       "          [0.3077, 0.3148, 0.3214, 0.3276]],\n",
       " \n",
       "         [[1.0000, 0.9545, 0.9167, 0.8846],\n",
       "          [0.8571, 0.8333, 0.8125, 0.7941],\n",
       "          [0.7778, 0.7632, 0.7500, 0.7381],\n",
       "          [0.7273, 0.7174, 0.7083, 0.7000],\n",
       "          [0.6923, 0.6852, 0.6786, 0.6724]]]),)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma = a.sum(axis = 0, keepdims = True) #在计算总和或平均时保持轴数不变\n",
    "afalse = a.sum(axis=0)\n",
    "a/suma, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 20.,  60., 100., 140., 180.]),\n",
       " tensor([[ 6.,  6.,  6.],\n",
       "         [22., 22., 22.],\n",
       "         [38., 38., 38.],\n",
       "         [54., 54., 54.],\n",
       "         [70., 70., 70.]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar = torch.tensor([1, 2, 3, 4], dtype=torch.float32)\n",
    "print(A.shape , ar.shape)\n",
    "B = torch.ones(4, 3)\n",
    "torch.mv(A, ar)  ,torch.mm(A, B) \n",
    "#矩阵*向量          #矩阵*矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([3, 5, 7]), tensor([ 3, 12]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.arange(6).reshape(2, 3)\n",
    "#对于matrix， 它是一个矩阵，行2 * 列3； 维度为2 。 \n",
    "# 那么它有两个轴，0轴为行 (长度为3) 、1轴为列（长度为2）\n",
    "\n",
    "print(matrix)\n",
    "matrix.sum(axis=0), matrix.sum(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "223e1489bc25012bb69e88158b96801209b93ea1897ec832a8be3ced267eea1d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
